{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd33bc2",
   "metadata": {},
   "source": [
    "##### Train model to predict images of digits using CLASSIC 2-Layer model and L-layer models.\n",
    "- These models were built without using any TensorFlow / Pytouch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4579388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical # convert your class labels into one-hot encoded vectors,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b2087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51c2772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000 images\n",
      "Number of testing examples: 10000 images\n",
      "Each image is of size: (28, 28, 3)\n",
      "-------------------------------------\n",
      "train_images shape: (60000, 28, 28)\n",
      "train_labels shape: (60000,)\n",
      "test_images shape: (10000, 28, 28)\n",
      "test_labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Number of training examples: \" + str(train_images.shape[0]) + \" images\")\n",
    "print (\"Number of testing examples: \" + str(test_images.shape[0]) + \" images\")\n",
    "print (\"Each image is of size: (\" + str(train_images.shape[1]) + \", \" + str(train_images.shape[1]) + \", 3)\")\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"train_images shape: \" + str(train_images.shape))\n",
    "print(\"train_labels shape: \" + str(train_labels.shape))\n",
    "print(\"test_images shape: \" + str(test_images.shape))\n",
    "print(\"test_labels shape: \" + str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e615a4",
   "metadata": {},
   "source": [
    "- In order for Dense layers to work later, we need to flatten the images (28x28) to 784-dimensional vectors for `train_images` and `test_images` so that they becomes a 2D array with shape of `(60000 , 784)` or `(10000 , 784)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96b4846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9e4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of output classes :  10\n",
      "All Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Check output classes\n",
    "total_classes = np.unique(train_labels)\n",
    "number_of_total_classes = len(total_classes)\n",
    "print('Total number of output classes : ', number_of_total_classes)\n",
    "print('All Output classes : ', total_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a494a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label : 2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first image in testing data \n",
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "plt.imshow(test_images[1,:,:], cmap='gray') # shows index 1 image of size 28 x 28 pixels \n",
    "plt.title(f\"Label : {test_labels[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b43200",
   "metadata": {},
   "source": [
    "#### Data Preprocessing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "542b4848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Resahpe from an array of dimension 28x28 to array of dimention 784 so that it becomes 2D array. \n",
    "train_x = train_images.reshape(train_images.shape[0], -1) # -1 will automatically be calculated into 28 * 28\n",
    "test_y = test_images.reshape(test_images.shape[0], -1)\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1. (255 is max pixel value for 8-bix grayscale image)\n",
    "train_x = train_x/255.\n",
    "test_x = test_y/255.\n",
    "\n",
    "# Change to float datatype\n",
    "train_data = train_x.astype('float32')\n",
    "test_data = test_x.astype('float32')\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a69eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Another way to flatten shape:\n",
    "# reshape = np.prod(train_images.shape[1:])  # = np.prod([28, 28]) = 784\n",
    "# train_data = train_images.reshape(train_images.shape[0], reshape)\n",
    "# test_data = test_images.reshape|(test_images.shape[0], reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa9a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoded labels\n",
    "train_y = to_categorical(train_labels)\n",
    "test_y = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1472cd",
   "metadata": {},
   "source": [
    "- In order to let our image be idenified and classified, we need to convert numeric labels into binary vectors \n",
    "- (E.g) label `3` becomes `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6520e42",
   "metadata": {},
   "source": [
    "#### Build Model: **2-Layer Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0625c74d",
   "metadata": {},
   "source": [
    "- It is an architecture of `LINEAR → RELU → LINEAR → SIGMOID`.\n",
    "\n",
    "- Linear activation function `f(x)=x`: output is directly proportional to the input. (output is same as input).\n",
    "\n",
    "- RELU (Rectified Linear Unit) `f(x)=max(0,x)`: It is a non-linear activation function that transforms any nagtive input to 0. \n",
    "\n",
    "- SIGMOID $f(x) = \\frac{1}{1 + e^{-x}}​$: It is a non-linear activation function that output values between 0 and 1. \n",
    "    - Where if `f(x)` > 0.5 = cat (1).\n",
    "    - Or if `f(x)` < 0.5 = not cat (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b06b59",
   "metadata": {},
   "source": [
    "- **Required Steps:**\n",
    "    - Initialize parameters\n",
    "        - weight (how important a feature is) and bias (baseline).\n",
    "\n",
    "    - Forward pass to compute activations at each layer: \n",
    "        - Linear transformation: `Z = W * A + b`.\n",
    "        - Activation functions (ReLU and Sigmoid): \n",
    "            - 1st linear transformation: apply ReLU (outputs values that is always non-nagative)\n",
    "            - 2nd linear transformation: apply Sigmoid (outputs probability between image digit (1) or not image digit (0))\n",
    "\n",
    "    - Compute cost (Cross-Entropy Loss formula)\n",
    "        - Formula is defined as: $- \\frac{1}{m} \\sum Y \\log(A)$\n",
    "        - Compares predicted outputs (A2) with actual labels (Y).\n",
    "        - Lower cost = Model's prediction closer to actual labels =  higher accuracy.\n",
    "\n",
    "    - Backward pass to compute gradients.\n",
    "        - Uses Backpropagation (based on the Calculus Chain Rule) to calculate how much each weight and bias contributed to the error.\n",
    "\n",
    "    - Update parameters.\n",
    "        - Adjusts $W$ and $b$ by subtracting a small portion (learning rate) of the gradients.\n",
    "\n",
    "    - Repeat for a number of iterations (Epochs) \n",
    "        - This iterative process of moving toward the lowest cost is called **gradient descent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff9f32",
   "metadata": {},
   "source": [
    "- *_Important note_:\n",
    "    - The cost formula here is different from linear regression model:\n",
    "    - Regression vs. Classification:\n",
    "        - MSE: This is designed for Regression (predicting a continuous number, like a house price). It measures the physical distance between the prediction and the target.\n",
    "\n",
    "        - Cross-Entropy: This is designed for Classification (predicting a category). It is based on information theory and measures the \"distance\" between two probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ae39b",
   "metadata": {},
   "source": [
    "- Define the layers:\n",
    "    - Input layer `(n_x)`: The number of input features (784).\n",
    "\n",
    "    - Hidden layer `(n_h)`: The number of hidden neurons in the hidden layer (128).\n",
    "        - Numbers can be `32, 64, 128, 256`. \n",
    "        - If we give too high number of neurons (256 etc), then model may **overfit**.\n",
    "\n",
    "    - Output layer `(n_y)`: The number of output neurons (10) since we have 10 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816fa02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    np.random.seed(7)  # For reproducibility\n",
    "    \n",
    "    # Initialize weights and biases for the layers\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01  # Weight for the first layer (size: n_h x n_x)\n",
    "    b1 = np.zeros((n_h, 1))  # Bias for the first layer (size: n_h x 1)\n",
    "    \n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01  # Weight for the second layer (size: n_y x n_h)\n",
    "    b2 = np.zeros((n_y, 1))  # Bias for the second layer (size: n_y x 1)\n",
    "\n",
    "    # Check the shape if it is correct\n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    # Store parameters in a dictionary to return\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb5191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc8329e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    Z = W.dot(A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "\n",
    "    return Z, cache\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc2f6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07dd635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29644307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss\n",
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c66888c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d569df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c8c29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "# n_x = 784  # Input layer size (28 * 28)\n",
    "# n_h = 128  # Hidden layer size (too big = overfit, too small = underfit)\n",
    "# n_y = 10    # Output layer size (binary classification)\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.007, num_iterations = 3000, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization.\n",
    "    ### START CODE HERE ###\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "        # Backward propagation.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        ### END CODE HERE ###\n",
    " \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = L_layer_model(X, Y, layers_dims, num_iterations = 250, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf24021",
   "metadata": {},
   "source": [
    "#### Testing model's prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b108a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    X: Input data (images) of shape (784)\n",
    "    y: One-hot encoded labels of shape (10)\n",
    "    parameters: Dictionary containing your trained W1, b1, W2, b2\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # 1. Forward pass to get probabilities (A2)\n",
    "    # Note: We transpose X to (784, m) for the forward pass\n",
    "    A1, _ = linear_activation_forward(X.T, parameters[\"W1\"], parameters[\"b1\"], activation=\"relu\")\n",
    "    A2, _ = linear_activation_forward(A1, parameters[\"W2\"], parameters[\"b2\"], activation=\"sigmoid\")\n",
    "    \n",
    "    # 2. Convert probabilities to class labels (0-9)\n",
    "    # axis=0 because A2 is (10, m). It picks the row index with highest value for each example.\n",
    "    predictions = np.argmax(A2, axis=0)\n",
    "    \n",
    "    # 3. Convert one-hot ground truth labels back to digits for comparison\n",
    "    true_labels = np.argmax(y.T, axis=0)\n",
    "    \n",
    "    # 4. Calculate accuracy\n",
    "    accuracy = np.mean(predictions == true_labels)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77690a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Accuracy ---\n",
      "Accuracy: 90.67%\n",
      "\n",
      "--- Test Accuracy ---\n",
      "Accuracy: 91.19%\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Training Accuracy ---\")\n",
    "p_train = predict(train_x, train_y, parameters)\n",
    "\n",
    "print(\"\\n--- Test Accuracy ---\")\n",
    "p_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f1ea16",
   "metadata": {},
   "source": [
    "- Based on the results above, the model has learned the actual patterns of the digits rather than just memorizing the training images. However, since both accuracy is at 90%, which indicates **High bias**, the model has not train long enough to capture finer details of the digits. \n",
    "\n",
    "- Possible Improvements:\n",
    "    - Increase the Epouch (from 500 to 1000) and hiddden layer size(from 128 to 256).\n",
    "    - Decrease learning rate size (from 0.1 to 0.001) to hit the minimum cost as close as possble.\n",
    "    - Add a 3rd layer (input -> hidden 1 -> hidden 2 -> output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6900fc",
   "metadata": {},
   "source": [
    "#### Building L-Layer Model\n",
    "- *[LINEAR -> RELU]$\\times$(L-1) -> LINEAR -> SIGMOID*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce06e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        # He Initialization (recommended for ReLU)\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2/layer_dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2   # number of layers\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1)\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation=\"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID (Output Layer)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation=\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) # number of layers\n",
    "    m = AL.shape[1]\n",
    "    \n",
    "    # Initializing the backpropagation (Direct dZ for Output Layer)\n",
    "    dZL = AL - Y.T\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients\n",
    "    current_cache = caches[L-1] # The last cache\n",
    "    A_prev, W, b, Z = current_cache\n",
    "    grads[\"dW\" + str(L)] = (1/m) * np.dot(dZL, A_prev.T)\n",
    "    grads[\"db\" + str(L)] = (1/m) * np.sum(dZL, axis=1, keepdims=True)\n",
    "    grads[\"dA\" + str(L-1)] = np.dot(W.T, dZL)\n",
    "    \n",
    "    # Loop from L-2 to 0 for hidden layers (RELU -> LINEAR)\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, activation=\"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a loop because of L layers\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.7396354611275338\n",
      "Cost after iteration 100: 0.4843130283571972\n",
      "Cost after iteration 200: 0.3345520984884648\n",
      "Cost after iteration 300: 0.2818175474545623\n",
      "Cost after iteration 400: 0.2459830787502518\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 256, 128, 64, 10] # 4-layer model\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate, num_iterations):\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Forward propagation\n",
    "        AL, caches = L_model_forward(X.T, parameters)\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = compute_cost(AL, Y)\n",
    "        \n",
    "        # Backward propagation\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        \n",
    "        # Update parameters\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Cost after iteration {i}: {cost}\")\n",
    "            costs.append(cost)\n",
    "            \n",
    "    return parameters, costs\n",
    "\n",
    "# Run training\n",
    "parameters, costs = L_layer_model(train_x, train_y, layers_dims,  learning_rate = 0.075, num_iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L-Model Prediction:\n",
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    X: Input data (images) of shape (m, 784)\n",
    "    y: One-hot encoded labels of shape (m, 10)\n",
    "    parameters: Dictionary containing all trained W and b for L layers\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # 1. Use the generalized Forward Pass function\n",
    "    # This automatically handles as many layers as are in your parameters dict\n",
    "    # AL will be the output of the very last (sigmoid) layer\n",
    "    AL, _ = L_model_forward(X.T, parameters)\n",
    "    \n",
    "    # 2. Convert probabilities to class labels (0-9)\n",
    "    # axis=0 because AL shape is (10, m)\n",
    "    predictions = np.argmax(AL, axis=0)\n",
    "    \n",
    "    # 3. Convert one-hot ground truth labels back to digits for comparison\n",
    "    # train_y/test_y are (m, 10), so we check axis 1\n",
    "    true_labels = np.argmax(y, axis=1)\n",
    "    \n",
    "    # 4. Calculate accuracy\n",
    "    accuracy = np.mean(predictions == true_labels)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde78286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- L-layer Model Training Accuracy ---\n",
      "Accuracy: 94.71%\n",
      "\n",
      "--- L-layer Model Test Accuracy ---\n",
      "Accuracy: 94.51%\n"
     ]
    }
   ],
   "source": [
    "# Assuming your layers_dims was [784, 128, 64, 10]\n",
    "print(\"--- L-layer Model Training Accuracy ---\")\n",
    "p_train = predict(train_x, train_y, parameters)\n",
    "\n",
    "print(\"\\n--- L-layer Model Test Accuracy ---\")\n",
    "p_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb8821",
   "metadata": {},
   "source": [
    "- As you can see, L-layer model has higher accuracy than 2 layer model of about 4% increment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc30b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User testing\n",
    "COLOR = 'white'\n",
    "plt.rcParams['text.color'] = COLOR\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "def predict_single(parameters, image, correct_label):\n",
    "    # 1. Preprocess the image: Flatten and Normalize\n",
    "    # Reshape from (28, 28) to (784, 1) and scale to 0-1\n",
    "    processed_image = image.reshape(784, 1) / 255.0\n",
    "    \n",
    "    # 2. Forward Pass using your manual function\n",
    "    # AL will be the output layer (probabilities for each digit)\n",
    "    AL, _ = L_model_forward(processed_image, parameters)\n",
    "    \n",
    "    # 3. Get the prediction\n",
    "    prediction_index = np.argmax(AL, axis=0)[0]\n",
    "    predicted_class = class_names[prediction_index]\n",
    "    \n",
    "    # 4. Show the result\n",
    "    show_image(image, class_names[correct_label], predicted_class)\n",
    "\n",
    "def show_image(img, label, guess):\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    plt.title(\"Expected: \" + label)\n",
    "    # Using a colored text for the prediction to make it stand out\n",
    "    plt.figtext(0.5, 0.90, f\"Model Guess: {guess}\", ha='center', fontsize=14, \n",
    "                color='green' if label == guess else 'red')\n",
    "    plt.show()\n",
    "\n",
    "def get_number():\n",
    "    while True:\n",
    "        num = input(\"Pick a number (0-9999): \")\n",
    "        if num.isdigit():\n",
    "            num = int(num)\n",
    "            if 0 <= num < 10000:\n",
    "                return num\n",
    "        print(\"Try again...\")\n",
    "\n",
    "# --- Execution ---\n",
    "num = get_number()\n",
    "image = test_images[num]   # Original 28x28 image for plotting\n",
    "label = test_labels[num]   # The integer label (0-9)\n",
    "predict_single(parameters, image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19052c8c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
